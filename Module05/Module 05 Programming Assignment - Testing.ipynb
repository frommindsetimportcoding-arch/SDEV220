{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "826a2383",
   "metadata": {},
   "source": [
    "# Nathan Thomas\n",
    "## SDEV220\n",
    "### Module 05 Programming Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0dbf82c",
   "metadata": {},
   "source": [
    "## Testing Your Code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75782bd7",
   "metadata": {},
   "source": [
    "> Checking the sum of numbers using assert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "25f5d518",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert sum([1,2,3]) == 6, 'Should be 6'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d666a7d0",
   "metadata": {},
   "source": [
    "> Using an incorrect result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a4eccf4",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Should be 6",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAssertionError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28msum\u001b[39m([\u001b[32m1\u001b[39m,\u001b[32m1\u001b[39m,\u001b[32m1\u001b[39m]) == \u001b[32m6\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mShould be 6\u001b[39m\u001b[33m'\u001b[39m\n",
      "\u001b[31mAssertionError\u001b[39m: Should be 6"
     ]
    }
   ],
   "source": [
    "assert sum([1,1,1]) == 6, 'Should be 6'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab8d357",
   "metadata": {},
   "source": [
    "> Stepping away from the REPL (Read, Eval, Print, Loop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0357bb32",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Everything passed\n"
     ]
    }
   ],
   "source": [
    "!python test_sum.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f11d2b23",
   "metadata": {},
   "source": [
    "> Adding *test_sum_tuple()* in a new file called *test_sum_2.py*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "954489f1",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \u001b[35m\"c:\\Users\\Nate\\Desktop\\IvyTech\\Spring2026\\SDEV220\\Module05\\test_sum_2.py\"\u001b[0m, line \u001b[35m9\u001b[0m, in \u001b[35m<module>\u001b[0m\n",
      "    \u001b[31mtest_sum_tuple\u001b[0m\u001b[1;31m()\u001b[0m\n",
      "    \u001b[31m~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^\u001b[0m\n",
      "  File \u001b[35m\"c:\\Users\\Nate\\Desktop\\IvyTech\\Spring2026\\SDEV220\\Module05\\test_sum_2.py\"\u001b[0m, line \u001b[35m5\u001b[0m, in \u001b[35mtest_sum_tuple\u001b[0m\n",
      "    assert \u001b[1;31msum((1,2,2)) == 6\u001b[0m, 'Should be 6'\n",
      "           \u001b[1;31m^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "\u001b[1;35mAssertionError\u001b[0m: \u001b[35mShould be 6\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python test_sum_2.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffd25c39",
   "metadata": {},
   "source": [
    "> Using *unittest* in *test_sum_unittest.py*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e159d94f",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".F\n",
      "======================================================================\n",
      "FAIL: test_sum_tuple (__main__.TestSum.test_sum_tuple)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Nate\\Desktop\\IvyTech\\Spring2026\\SDEV220\\Module05\\test_sum_unittest.py\", line 10, in test_sum_tuple\n",
      "    self.assertEqual(sum((1, 2, 2)), 6, 'Should be 6')\n",
      "    ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AssertionError: 5 != 6 : Should be 6\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 2 tests in 0.001s\n",
      "\n",
      "FAILED (failures=1)\n"
     ]
    }
   ],
   "source": [
    "!python test_sum_unittest.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2efe06e2",
   "metadata": {},
   "source": [
    "> The next section wanted us to install nose2. I would much rather install pytest and familiarize myself with this test runner. Following the installation of nose 2 you would run the **python -m nose2** to execute the previously created unittest. *pytest* looks much more appealing, but the tutorial only describes a test case example without instruction on the architecture needed to apply it to your project. I will learn this on my own. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df42351",
   "metadata": {},
   "source": [
    "## Writing Your First Python Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1867d0f6",
   "metadata": {},
   "source": [
    "> I used the Module05 folder as my 'project folder' and created a module following the same architecture described in the tutorial."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bd963ac",
   "metadata": {},
   "source": [
    "```\n",
    "Module05/\n",
    "│\n",
    "└── my_sum/\n",
    "    └── __init__.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d710da4",
   "metadata": {},
   "source": [
    "> We create a function in __init__.py called sum() (little sketchy) and we create a test.py file within the Module05 folder so that it is siblings with the my_sum module folder."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f55185",
   "metadata": {},
   "source": [
    "```\n",
    "Module05/\n",
    "│\n",
    "├── my_sum/\n",
    "│   └── __init__.py\n",
    "│\n",
    "└── test.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c15e230",
   "metadata": {},
   "source": [
    "## Executing Your First Python Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd5ce68",
   "metadata": {},
   "source": [
    "> Because we added if __name__ == '__main__': and pointed it to unittest.main(), when we run python test.py it will call unittest.main(). This looks for all classes in the file that inherit from **unittest.Testcase**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1335b0fe",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 0.000s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "!python test.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39c40789",
   "metadata": {},
   "source": [
    "> Or you can run the *test.py* script by directly calling unit test like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f5706566",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 0.000s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "!python -m unittest test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fffbc4b",
   "metadata": {},
   "source": [
    "> Same direct call using the verbose flag -v."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "381fbd53",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_list_int (test.TestSum.test_list_int)\n",
      "Test that is can sum a list of integers ... ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 0.000s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "!python -m unittest -v test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef2081f1",
   "metadata": {},
   "source": [
    ">Here is a way to request an autodiscovery to search current directory for any files named test*.py. This ought to be interesting. Throwing the verbose flag in to see how it handles both test.py files that utilize the unittest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2f70b807",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_list_int (test.TestSum.test_list_int)\n",
      "Test that is can sum a list of integers ... ok\n",
      "test_sum (test_sum_unittest.TestSum.test_sum) ... ok\n",
      "test_sum_tuple (test_sum_unittest.TestSum.test_sum_tuple) ... FAIL\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_sum_tuple (test_sum_unittest.TestSum.test_sum_tuple)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Nate\\Desktop\\IvyTech\\Spring2026\\SDEV220\\Module05\\test_sum_unittest.py\", line 10, in test_sum_tuple\n",
      "    self.assertEqual(sum((1, 2, 2)), 6, 'Should be 6')\n",
      "    ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AssertionError: 5 != 6 : Should be 6\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 3 tests in 0.001s\n",
      "\n",
      "FAILED (failures=1)\n"
     ]
    }
   ],
   "source": [
    "!python -m unittest discover -v"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b770d55",
   "metadata": {},
   "source": [
    "> I don't think this one will work because I didn't make a test directory. But let's see what happens.\n",
    "> **-s tests** does not work and throws an error, but **-s test** does so it must search more than the directory. Or maybe it is included with the **unittest discover** operation and neglects the **-s test**.  but **-s tests** definitely throws an error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "744f946c",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "..F\n",
      "======================================================================\n",
      "FAIL: test_sum_tuple (test_sum_unittest.TestSum.test_sum_tuple)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Nate\\Desktop\\IvyTech\\Spring2026\\SDEV220\\Module05\\test_sum_unittest.py\", line 10, in test_sum_tuple\n",
      "    self.assertEqual(sum((1, 2, 2)), 6, 'Should be 6')\n",
      "    ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AssertionError: 5 != 6 : Should be 6\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 3 tests in 0.001s\n",
      "\n",
      "FAILED (failures=1)\n"
     ]
    }
   ],
   "source": [
    "!python -m unittest discover -s test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2c44914",
   "metadata": {},
   "source": [
    "> The next line of code would be used to search a subdirectory if the source code files are not in the root directory with the test scripts. Left out an argument since they are in the same level directory anyway."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6dbdc5fa",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: python.exe -m unittest discover [-h] [-v] [-q] [--locals]\n",
      "                                       [--durations N] [-f] [-c] [-b]\n",
      "                                       [-k TESTNAMEPATTERNS] [-s START]\n",
      "                                       [-p PATTERN] [-t TOP]\n",
      "python.exe -m unittest discover: error: argument -t/--top-level-directory: expected one argument\n"
     ]
    }
   ],
   "source": [
    "!python -m unittest discover -s tests -t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef64976",
   "metadata": {},
   "source": [
    "> Forcing a failure. Adding fractions to **test.py**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "86190904",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F.\n",
      "======================================================================\n",
      "FAIL: test_list_fraction (__main__.TestSum.test_list_fraction)\n",
      "Test that it can sum a list of fractions\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Nate\\Desktop\\IvyTech\\Spring2026\\SDEV220\\Module05\\test.py\", line 22, in test_list_fraction\n",
      "    self.assertEqual(result, 1)\n",
      "    ~~~~~~~~~~~~~~~~^^^^^^^^^^^\n",
      "AssertionError: Fraction(9, 10) != 1\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 2 tests in 0.001s\n",
      "\n",
      "FAILED (failures=1)\n"
     ]
    }
   ],
   "source": [
    "!python test.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3abe2680",
   "metadata": {},
   "source": [
    "> The results above were a forced error because the application technically works. 9/10 would be the correct answer. But what we are told is the name of the test **test_list_fraction**. It also tells you the test case **TestSum** that failed. Then we can see what line the test code failed at **line 22** and what test function that it failed in **test_list_fraction**. It gives us an AssertionError: Telling us that the result did not equal 1. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
